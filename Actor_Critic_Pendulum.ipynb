{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actor Critic Pendulum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython import display\n",
    "from IPython.display import HTML\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions import Normal, Categorical\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_torch_model(model, filename):\n",
    "  if not os.path.exists(os.path.dirname(filename)):\n",
    "    os.makedirs(os.path.dirname(filename))\n",
    "  torch.save(model.state_dict(), filename)\n",
    "\n",
    "def load_torch_model(model, filename):\n",
    "  model.load_state_dict(torch.load(filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_grad(source, target):\n",
    "  grads = []\n",
    "  for param in source.parameters():\n",
    "    grads.append(param.grad.clone())\n",
    "  grads.reverse()\n",
    "  for param in target.parameters():\n",
    "    param.grad = grads.pop()\n",
    "\n",
    "def zero_grad(model):\n",
    "  for param in model.parameters():\n",
    "    if type(param.grad) != type(None):\n",
    "      param.grad.data.zero_()\n",
    "      \n",
    "def update_target(target_net, eval_net, tau):\n",
    "  fast = eval_net.state_dict()\n",
    "  slow = target_net.state_dict()\n",
    "  for t in slow:\n",
    "    slow[t] = slow[t] * (1. - tau) + fast[t] * tau\n",
    "\n",
    "  target_net.load_state_dict(slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNet_continuous(nn.Module):\n",
    "  def __init__(self, input_size, output_size):\n",
    "    super(PolicyNet_continuous,self).__init__()\n",
    "    self.l1_linear = nn.Linear(input_size,256)\n",
    "    self.l2_linear = nn.Linear(256,128)\n",
    "    self.l3_linear = nn.Linear(128,output_size)\n",
    "    nn.init.kaiming_normal_(self.l1_linear.weight)\n",
    "    nn.init.kaiming_normal_(self.l2_linear.weight)\n",
    "    self.l3_linear.weight.data.zero_()\n",
    "    \n",
    "  def forward(self,x):\n",
    "    out = F.relu(self.l1_linear(x))\n",
    "    out = F.relu(self.l2_linear(out))\n",
    "    out = F.tanh(self.l3_linear(out))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueNet(nn.Module):\n",
    "  def __init__(self, input_size):\n",
    "    super(ValueNet,self).__init__()\n",
    "    self.l1_linear = nn.Linear(input_size, 256)\n",
    "    self.l2_linear = nn.Linear(256,128)\n",
    "    self.l3_linear = nn.Linear(128, 1)\n",
    "    nn.init.kaiming_normal_(self.l1_linear.weight)\n",
    "    nn.init.kaiming_normal_(self.l2_linear.weight)\n",
    "    self.l3_linear.weight.data.zero_()\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = F.relu(self.l1_linear(x))\n",
    "    out = F.relu(self.l2_linear(out))\n",
    "    out = self.l3_linear(out)\n",
    "    return out    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCritic_continuous():\n",
    "  def __init__(self, env, steps_in_state = 2):\n",
    "    self.steps_in_state = steps_in_state\n",
    "    self.policy_target = PolicyNet_discret(env.observation_space.shape[0] * steps_in_state, env.action_space.shape[0])\n",
    "    self.value_target = ValueNet(env.observation_space.shape[0] * steps_in_state)\n",
    "    if use_cuda:\n",
    "      self.policy_target.cuda()\n",
    "      self.value_target.cuda()\n",
    "    self.env = env\n",
    "    self.range_scale = (env.action_space.high[0] - env.action_space.low[0]) / 2.0\n",
    "\n",
    "    self._gamma = 0.96\n",
    "    \n",
    "  def pick_action(self, state):\n",
    "    probs = self.policy_target(state) * self.range_scale\n",
    "    action_dist = Normal(probs, 0.01)\n",
    "    action = action_dist.rsample()\n",
    "    action = action.item()\n",
    "    action = np.clip(action,-1.0,1.0)\n",
    "    return (action, action_dist.log_prob(FloatTensor([action])))\n",
    "  \n",
    "  def update_actor_critic(self, episode):\n",
    "    (states, actions, rewards, next_states, log_probs, ended) = zip(*episode)\n",
    "    \n",
    "    rewards = FloatTensor(rewards)\n",
    "    ended = FloatTensor(ended)\n",
    "    state_value = self.value_target(torch.stack(states))\n",
    "    next_state_value = self.value_target(torch.stack(next_states))\n",
    "    target_value = rewards + (1 - ended) * self._gamma * next_state_value\n",
    "    \n",
    "    delta = target_value - state_value\n",
    "\n",
    "    value_loss = F.mse_loss(state_value, target_value)\n",
    "    \n",
    "    policy_loss = []\n",
    "    for log_prob, d in zip(log_probs, delta):\n",
    "      policy_loss.append(-log_prob * d)\n",
    "    policy_loss = torch.stack(policy_loss).sum()\n",
    "    \n",
    "    self.value_optimizer.zero_grad()\n",
    "    value_loss.backward(retain_graph=True)\n",
    "    self.value_optimizer.step()\n",
    "    \n",
    "    self.policy_optimizer.zero_grad()\n",
    "    policy_loss.backward()\n",
    "    self.policy_optimizer.step()\n",
    "    \n",
    "  def train(self, env, update_limit=1000, samples_per_update=200, lr=1e-3, lr_policy=None, lr_value=None, checkpoint=100):\n",
    "    lr_policy = lr if lr_policy == None else lr_policy\n",
    "    lr_value = lr if lr_value == None else lr_value\n",
    "    self.policy_optimizer = torch.optim.SGD(self.policy_target.parameters(), lr=lr_policy, weight_decay=1e-3)\n",
    "    self.value_optimizer = torch.optim.SGD(self.value_target.parameters(), lr=lr_value, weight_decay=1e-3)\n",
    "    best_score = -99999\n",
    "    running_score = None\n",
    "    samples = []\n",
    "    samples_per_update = samples_per_update\n",
    "    update_count = 0\n",
    "    while update_count < update_limit:\n",
    "      s0 = env.reset()\n",
    "      s0[2] /= 8.\n",
    "      seq = [s0] * self.steps_in_state\n",
    "      state = FloatTensor(seq).view(-1)\n",
    "      episode = []\n",
    "      episode_ended = False\n",
    "      score = 0\n",
    "      while not episode_ended:\n",
    "        (action, log_prob) =  self.pick_action(state)\n",
    "        (s1, reward, episode_ended, info) = env.step([action * 2.0])\n",
    "        s1[2] /= 8.\n",
    "        seq = seq[1:]\n",
    "        seq.append(s1)\n",
    "        next_state = FloatTensor(seq).view(-1)\n",
    "        if episode_ended:\n",
    "          ended = 1\n",
    "        else:\n",
    "          ended = 0\n",
    "        samples.append((state, action, reward, next_state, log_prob, ended))\n",
    "\n",
    "        s0 = s1\n",
    "        state = next_state\n",
    "        score += reward\n",
    "        \n",
    "      if running_score == None:\n",
    "        running_score = score\n",
    "      else:\n",
    "        running_score = running_score * 0.9 + score * 0.1\n",
    "        \n",
    "      if len(samples) > samples_per_update:\n",
    "        if (update_count + 1) % checkpoint == 0:\n",
    "          is_best = False\n",
    "          if running_score > best_score:\n",
    "            is_best = True\n",
    "            save_torch_model(self.policy_target, 'model/actor_critic_cartpole_policy_best.pth')\n",
    "            best_score = running_score\n",
    "          save_torch_model(self.policy_target,'model/actor_critic_cartpole_policy_iter_%d.pth' %(update_count+1))\n",
    "          print('%d: running_score:%.2f, is_best:%s' %(update_count+1, running_score, is_best))\n",
    "        update_count += 1\n",
    "        self.update_actor_critic(samples)\n",
    "        samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCritic_target_eval_continuous():\n",
    "  def __init__(self, env, steps_in_state = 2):\n",
    "    self.steps_in_state = steps_in_state\n",
    "    self.policy_target = PolicyNet_discret(env.observation_space.shape[0] * steps_in_state, env.action_space.shape[0])\n",
    "    self.policy_eval = PolicyNet_discret(env.observation_space.shape[0] * steps_in_state, env.action_space.shape[0])\n",
    "    self.value_target = ValueNet(env.observation_space.shape[0] * steps_in_state)\n",
    "    self.value_eval = ValueNet(env.observation_space.shape[0] * steps_in_state)\n",
    "    if use_cuda:\n",
    "      self.policy_target.cuda()\n",
    "      self.policy_eval.cuda()\n",
    "      self.value_target.cuda()\n",
    "      self.value_eval.cuda()\n",
    "    self.policy_eval.load_state_dict(self.policy_target.state_dict())\n",
    "    self.value_eval.load_state_dict(self.value_target.state_dict())\n",
    "    self.env = env\n",
    "    self.range_scale = (env.action_space.high[0] - env.action_space.low[0]) / 2.0\n",
    "\n",
    "    self._gamma = 0.96\n",
    "    \n",
    "  def pick_action(self, state):\n",
    "    probs = self.policy_target(state) \n",
    "    action_dist = Normal(probs, 0.01)\n",
    "    action = action_dist.rsample()\n",
    "    action = action.item()\n",
    "    action = np.clip(action, -1.0, 1.0)\n",
    "    return (action, action_dist.log_prob(FloatTensor([action])))\n",
    "  \n",
    "  def update_actor_critic(self, episode):\n",
    "    (states, actions, rewards, next_states, log_probs, ended) = zip(*episode)\n",
    "    \n",
    "    rewards = FloatTensor(rewards)\n",
    "    ended = FloatTensor(ended)\n",
    "    state_value = self.value_target(torch.stack(states))\n",
    "    next_state_value = self.value_target(torch.stack(next_states))\n",
    "    target_value = rewards + (1 - ended) * self._gamma * next_state_value\n",
    "    \n",
    "    delta = target_value - state_value\n",
    "\n",
    "    value_loss = F.mse_loss(state_value, target_value)\n",
    "    \n",
    "    policy_loss = []\n",
    "    for log_prob, d in zip(log_probs, delta):\n",
    "      policy_loss.append(-log_prob * d)\n",
    "    policy_loss = torch.stack(policy_loss).sum()\n",
    "    \n",
    "    self.value_optimizer.zero_grad()\n",
    "    zero_grad(self.value_target)\n",
    "    value_loss.backward(retain_graph=True)\n",
    "    copy_grad(self.value_target, self.value_eval)\n",
    "    self.value_optimizer.step()\n",
    "    \n",
    "    self.policy_optimizer.zero_grad()\n",
    "    zero_grad(self.policy_target)\n",
    "    policy_loss.backward()\n",
    "    copy_grad(self.policy_target, self.policy_eval)\n",
    "    self.policy_optimizer.step()\n",
    "    \n",
    "  def train(self, env, update_limit=1000, samples_per_update=200, lr=1e-3, lr_policy=None, lr_value=None, checkpoint=100):\n",
    "    lr_policy = lr if lr_policy == None else lr_policy\n",
    "    lr_value = lr if lr_value == None else lr_value\n",
    "    self.policy_optimizer = torch.optim.SGD(self.policy_eval.parameters(), lr=lr_policy, weight_decay=1e-3)\n",
    "    self.value_optimizer = torch.optim.SGD(self.value_eval.parameters(), lr=lr_value, weight_decay=1e-3)\n",
    "    best_score = -99999\n",
    "    running_score = None\n",
    "    samples = []\n",
    "    samples_per_update = samples_per_update\n",
    "    update_count = 0\n",
    "    while update_count < update_limit:\n",
    "      s0 = env.reset()\n",
    "      seq = [s0] * self.steps_in_state\n",
    "      state = FloatTensor(seq).view(-1)\n",
    "      episode = []\n",
    "      episode_ended = False\n",
    "      score = 0\n",
    "      while not episode_ended:\n",
    "        (action, log_prob) =  self.pick_action(state)\n",
    "        (s1, reward, episode_ended, info) = env.step([action * 2.0])\n",
    "        seq = seq[1:]\n",
    "        seq.append(s1)\n",
    "        next_state = FloatTensor(seq).view(-1)\n",
    "        if episode_ended:\n",
    "          ended = 1\n",
    "        else:\n",
    "          ended = 0\n",
    "        samples.append((state, action, reward, next_state, log_prob, ended))\n",
    "\n",
    "        s0 = s1\n",
    "        state = next_state\n",
    "        score += reward\n",
    "        \n",
    "      if running_score == None:\n",
    "        running_score = score\n",
    "      else:\n",
    "        running_score = running_score * 0.9 + score * 0.1\n",
    "        \n",
    "      if len(samples) > samples_per_update:\n",
    "        if (update_count + 1) % checkpoint == 0:\n",
    "          is_best = False\n",
    "          if running_score > best_score:\n",
    "            is_best = True\n",
    "            save_torch_model(self.policy_target, 'model/actor_critic_cartpole_policy_best.pth')\n",
    "            best_score = running_score\n",
    "          save_torch_model(self.policy_target,'model/actor_critic_cartpole_policy_iter_%d.pth' %(update_count+1))\n",
    "          print('%d: running_score:%.2f, is_best:%s' %(update_count+1, running_score, is_best))\n",
    "        update_count += 1\n",
    "        self.update_actor_critic(samples)\n",
    "        samples = []\n",
    "        \n",
    "        if (update_count + 1) % 20 == 0:\n",
    "          update_target(self.policy_target, self.policy_eval, 0.1)\n",
    "          update_target(self.value_target, self.value_eval, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Pendulum-v0')\n",
    "agent = ActorCritic_continuous(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100: running_score:-1398.54, is_best:True\n",
      "200: running_score:-1450.90, is_best:False\n",
      "300: running_score:-1499.19, is_best:False\n",
      "400: running_score:-1422.71, is_best:False\n",
      "500: running_score:-1446.01, is_best:False\n",
      "600: running_score:-1331.19, is_best:True\n",
      "700: running_score:-1313.73, is_best:True\n",
      "800: running_score:-1436.07, is_best:False\n",
      "900: running_score:-1476.28, is_best:False\n",
      "1000: running_score:-1495.54, is_best:False\n",
      "1100: running_score:-1516.20, is_best:False\n",
      "1200: running_score:-1395.03, is_best:False\n",
      "1300: running_score:-1520.37, is_best:False\n",
      "1400: running_score:-1486.66, is_best:False\n",
      "1500: running_score:-1350.49, is_best:False\n",
      "1600: running_score:-1399.30, is_best:False\n",
      "1700: running_score:-1429.65, is_best:False\n",
      "1800: running_score:-1420.74, is_best:False\n",
      "1900: running_score:-1449.31, is_best:False\n",
      "2000: running_score:-1362.80, is_best:False\n",
      "2100: running_score:-1494.58, is_best:False\n",
      "2200: running_score:-1462.82, is_best:False\n",
      "2300: running_score:-1426.00, is_best:False\n",
      "2400: running_score:-1501.03, is_best:False\n",
      "2500: running_score:-1433.23, is_best:False\n",
      "2600: running_score:-1423.08, is_best:False\n",
      "2700: running_score:-1378.51, is_best:False\n",
      "2800: running_score:-1415.77, is_best:False\n",
      "2900: running_score:-1463.10, is_best:False\n",
      "3000: running_score:-1510.76, is_best:False\n",
      "3100: running_score:-1383.22, is_best:False\n",
      "3200: running_score:-1414.40, is_best:False\n",
      "3300: running_score:-1504.82, is_best:False\n",
      "3400: running_score:-1409.31, is_best:False\n",
      "3500: running_score:-1356.51, is_best:False\n",
      "3600: running_score:-1469.75, is_best:False\n",
      "3700: running_score:-1432.47, is_best:False\n",
      "3800: running_score:-1505.57, is_best:False\n",
      "3900: running_score:-1388.93, is_best:False\n",
      "4000: running_score:-1426.89, is_best:False\n",
      "4100: running_score:-1470.03, is_best:False\n",
      "4200: running_score:-1491.14, is_best:False\n",
      "4300: running_score:-1448.34, is_best:False\n",
      "4400: running_score:-1462.89, is_best:False\n",
      "4500: running_score:-1328.57, is_best:False\n",
      "4600: running_score:-1382.86, is_best:False\n",
      "4700: running_score:-1440.53, is_best:False\n",
      "4800: running_score:-1397.74, is_best:False\n",
      "4900: running_score:-1469.38, is_best:False\n",
      "5000: running_score:-1403.61, is_best:False\n",
      "5100: running_score:-1398.26, is_best:False\n",
      "5200: running_score:-1429.52, is_best:False\n",
      "5300: running_score:-1430.75, is_best:False\n",
      "5400: running_score:-1401.29, is_best:False\n",
      "5500: running_score:-1505.57, is_best:False\n",
      "5600: running_score:-1381.97, is_best:False\n",
      "5700: running_score:-1419.78, is_best:False\n",
      "5800: running_score:-1458.46, is_best:False\n",
      "5900: running_score:-1481.85, is_best:False\n",
      "6000: running_score:-1431.21, is_best:False\n",
      "6100: running_score:-1384.92, is_best:False\n",
      "6200: running_score:-1479.76, is_best:False\n",
      "6300: running_score:-1516.63, is_best:False\n",
      "6400: running_score:-1471.28, is_best:False\n",
      "6500: running_score:-1518.70, is_best:False\n",
      "6600: running_score:-1463.34, is_best:False\n",
      "6700: running_score:-1507.08, is_best:False\n",
      "6800: running_score:-1388.90, is_best:False\n",
      "6900: running_score:-1425.88, is_best:False\n",
      "7000: running_score:-1418.16, is_best:False\n",
      "7100: running_score:-1449.17, is_best:False\n",
      "7200: running_score:-1436.05, is_best:False\n",
      "7300: running_score:-1520.27, is_best:False\n",
      "7400: running_score:-1368.17, is_best:False\n",
      "7500: running_score:-1454.56, is_best:False\n",
      "7600: running_score:-1458.51, is_best:False\n",
      "7700: running_score:-1420.31, is_best:False\n",
      "7800: running_score:-1409.00, is_best:False\n",
      "7900: running_score:-1359.34, is_best:False\n",
      "8000: running_score:-1521.76, is_best:False\n",
      "8100: running_score:-1493.93, is_best:False\n",
      "8200: running_score:-1392.69, is_best:False\n",
      "8300: running_score:-1380.02, is_best:False\n",
      "8400: running_score:-1379.87, is_best:False\n",
      "8500: running_score:-1454.44, is_best:False\n",
      "8600: running_score:-1467.95, is_best:False\n",
      "8700: running_score:-1403.03, is_best:False\n",
      "8800: running_score:-1539.01, is_best:False\n",
      "8900: running_score:-1368.32, is_best:False\n",
      "9000: running_score:-1446.73, is_best:False\n",
      "9100: running_score:-1262.81, is_best:True\n",
      "9200: running_score:-1358.84, is_best:False\n",
      "9300: running_score:-1472.92, is_best:False\n",
      "9400: running_score:-1431.70, is_best:False\n",
      "9500: running_score:-1432.03, is_best:False\n",
      "9600: running_score:-1524.54, is_best:False\n",
      "9700: running_score:-1409.06, is_best:False\n",
      "9800: running_score:-1460.33, is_best:False\n",
      "9900: running_score:-1345.82, is_best:False\n",
      "10000: running_score:-1454.67, is_best:False\n",
      "10100: running_score:-1485.96, is_best:False\n",
      "10200: running_score:-1492.75, is_best:False\n",
      "10300: running_score:-1500.59, is_best:False\n",
      "10400: running_score:-1476.81, is_best:False\n",
      "10500: running_score:-1486.40, is_best:False\n",
      "10600: running_score:-1395.71, is_best:False\n",
      "10700: running_score:-1463.72, is_best:False\n",
      "10800: running_score:-1435.63, is_best:False\n",
      "10900: running_score:-1431.37, is_best:False\n",
      "11000: running_score:-1461.01, is_best:False\n",
      "11100: running_score:-1422.89, is_best:False\n",
      "11200: running_score:-1510.41, is_best:False\n",
      "11300: running_score:-1401.40, is_best:False\n",
      "11400: running_score:-1546.83, is_best:False\n",
      "11500: running_score:-1465.27, is_best:False\n",
      "11600: running_score:-1377.23, is_best:False\n",
      "11700: running_score:-1486.86, is_best:False\n",
      "11800: running_score:-1438.17, is_best:False\n",
      "11900: running_score:-1481.49, is_best:False\n",
      "12000: running_score:-1464.69, is_best:False\n",
      "12100: running_score:-1445.29, is_best:False\n",
      "12200: running_score:-1420.89, is_best:False\n",
      "12300: running_score:-1479.28, is_best:False\n",
      "12400: running_score:-1452.72, is_best:False\n",
      "12500: running_score:-1442.61, is_best:False\n",
      "12600: running_score:-1476.22, is_best:False\n",
      "12700: running_score:-1376.02, is_best:False\n",
      "12800: running_score:-1343.94, is_best:False\n",
      "12900: running_score:-1392.98, is_best:False\n",
      "13000: running_score:-1413.19, is_best:False\n",
      "13100: running_score:-1480.55, is_best:False\n",
      "13200: running_score:-1482.61, is_best:False\n",
      "13300: running_score:-1417.10, is_best:False\n",
      "13400: running_score:-1470.34, is_best:False\n",
      "13500: running_score:-1441.24, is_best:False\n",
      "13600: running_score:-1485.71, is_best:False\n",
      "13700: running_score:-1473.30, is_best:False\n",
      "13800: running_score:-1340.89, is_best:False\n",
      "13900: running_score:-1342.19, is_best:False\n",
      "14000: running_score:-1293.93, is_best:False\n",
      "14100: running_score:-1554.96, is_best:False\n",
      "14200: running_score:-1375.61, is_best:False\n",
      "14300: running_score:-1376.72, is_best:False\n",
      "14400: running_score:-1494.84, is_best:False\n",
      "14500: running_score:-1464.88, is_best:False\n",
      "14600: running_score:-1418.76, is_best:False\n",
      "14700: running_score:-1478.25, is_best:False\n",
      "14800: running_score:-1416.74, is_best:False\n",
      "14900: running_score:-1380.13, is_best:False\n",
      "15000: running_score:-1378.74, is_best:False\n",
      "15100: running_score:-1455.42, is_best:False\n",
      "15200: running_score:-1507.94, is_best:False\n",
      "15300: running_score:-1470.99, is_best:False\n",
      "15400: running_score:-1429.20, is_best:False\n",
      "15500: running_score:-1437.85, is_best:False\n",
      "15600: running_score:-1423.62, is_best:False\n",
      "15700: running_score:-1399.81, is_best:False\n",
      "15800: running_score:-1471.41, is_best:False\n",
      "15900: running_score:-1456.51, is_best:False\n",
      "16000: running_score:-1348.26, is_best:False\n",
      "16100: running_score:-1360.93, is_best:False\n",
      "16200: running_score:-1504.46, is_best:False\n",
      "16300: running_score:-1323.56, is_best:False\n",
      "16400: running_score:-1500.91, is_best:False\n",
      "16500: running_score:-1394.09, is_best:False\n",
      "16600: running_score:-1302.69, is_best:False\n",
      "16700: running_score:-1500.52, is_best:False\n",
      "16800: running_score:-1389.04, is_best:False\n",
      "16900: running_score:-1412.64, is_best:False\n",
      "17000: running_score:-1549.28, is_best:False\n",
      "17100: running_score:-1497.65, is_best:False\n",
      "17200: running_score:-1385.24, is_best:False\n",
      "17300: running_score:-1431.28, is_best:False\n",
      "17400: running_score:-1282.77, is_best:False\n",
      "17500: running_score:-1391.94, is_best:False\n",
      "17600: running_score:-1491.30, is_best:False\n",
      "17700: running_score:-1410.33, is_best:False\n",
      "17800: running_score:-1428.62, is_best:False\n",
      "17900: running_score:-1406.95, is_best:False\n",
      "18000: running_score:-1409.31, is_best:False\n",
      "18100: running_score:-1400.55, is_best:False\n",
      "18200: running_score:-1475.05, is_best:False\n",
      "18300: running_score:-1448.71, is_best:False\n",
      "18400: running_score:-1455.99, is_best:False\n",
      "18500: running_score:-1356.52, is_best:False\n",
      "18600: running_score:-1481.40, is_best:False\n",
      "18700: running_score:-1419.63, is_best:False\n",
      "18800: running_score:-1397.81, is_best:False\n",
      "18900: running_score:-1397.40, is_best:False\n",
      "19000: running_score:-1372.33, is_best:False\n",
      "19100: running_score:-1453.83, is_best:False\n",
      "19200: running_score:-1421.15, is_best:False\n",
      "19300: running_score:-1369.28, is_best:False\n",
      "19400: running_score:-1366.09, is_best:False\n",
      "19500: running_score:-1439.94, is_best:False\n",
      "19600: running_score:-1358.66, is_best:False\n",
      "19700: running_score:-1428.66, is_best:False\n",
      "19800: running_score:-1397.67, is_best:False\n",
      "19900: running_score:-1526.09, is_best:False\n",
      "20000: running_score:-1316.96, is_best:False\n",
      "20100: running_score:-1498.54, is_best:False\n",
      "20200: running_score:-1382.43, is_best:False\n",
      "20300: running_score:-1468.92, is_best:False\n",
      "20400: running_score:-1460.69, is_best:False\n",
      "20500: running_score:-1493.99, is_best:False\n",
      "20600: running_score:-1525.30, is_best:False\n",
      "20700: running_score:-1463.05, is_best:False\n",
      "20800: running_score:-1414.87, is_best:False\n",
      "20900: running_score:-1394.70, is_best:False\n",
      "21000: running_score:-1415.00, is_best:False\n",
      "21100: running_score:-1403.62, is_best:False\n",
      "21200: running_score:-1417.89, is_best:False\n",
      "21300: running_score:-1531.66, is_best:False\n",
      "21400: running_score:-1409.56, is_best:False\n",
      "21500: running_score:-1429.66, is_best:False\n",
      "21600: running_score:-1379.28, is_best:False\n",
      "21700: running_score:-1386.54, is_best:False\n",
      "21800: running_score:-1418.19, is_best:False\n",
      "21900: running_score:-1514.37, is_best:False\n",
      "22000: running_score:-1430.01, is_best:False\n",
      "22100: running_score:-1510.14, is_best:False\n",
      "22200: running_score:-1459.70, is_best:False\n",
      "22300: running_score:-1385.71, is_best:False\n",
      "22400: running_score:-1449.38, is_best:False\n",
      "22500: running_score:-1412.64, is_best:False\n",
      "22600: running_score:-1434.70, is_best:False\n",
      "22700: running_score:-1350.74, is_best:False\n",
      "22800: running_score:-1419.13, is_best:False\n",
      "22900: running_score:-1372.46, is_best:False\n",
      "23000: running_score:-1456.87, is_best:False\n",
      "23100: running_score:-1480.39, is_best:False\n",
      "23200: running_score:-1442.60, is_best:False\n",
      "23300: running_score:-1435.67, is_best:False\n",
      "23400: running_score:-1406.31, is_best:False\n",
      "23500: running_score:-1310.98, is_best:False\n",
      "23600: running_score:-1407.83, is_best:False\n",
      "23700: running_score:-1428.95, is_best:False\n",
      "23800: running_score:-1455.65, is_best:False\n",
      "23900: running_score:-1431.85, is_best:False\n",
      "24000: running_score:-1507.32, is_best:False\n",
      "24100: running_score:-1474.99, is_best:False\n",
      "24200: running_score:-1327.23, is_best:False\n",
      "24300: running_score:-1398.28, is_best:False\n",
      "24400: running_score:-1420.17, is_best:False\n",
      "24500: running_score:-1474.97, is_best:False\n",
      "24600: running_score:-1492.06, is_best:False\n",
      "24700: running_score:-1409.64, is_best:False\n",
      "24800: running_score:-1250.68, is_best:True\n",
      "24900: running_score:-1350.10, is_best:False\n",
      "25000: running_score:-1416.18, is_best:False\n",
      "25100: running_score:-1475.48, is_best:False\n",
      "25200: running_score:-1515.32, is_best:False\n",
      "25300: running_score:-1464.54, is_best:False\n",
      "25400: running_score:-1420.00, is_best:False\n",
      "25500: running_score:-1424.78, is_best:False\n",
      "25600: running_score:-1473.39, is_best:False\n",
      "25700: running_score:-1370.06, is_best:False\n",
      "25800: running_score:-1475.16, is_best:False\n",
      "25900: running_score:-1390.10, is_best:False\n",
      "26000: running_score:-1475.97, is_best:False\n",
      "26100: running_score:-1419.37, is_best:False\n",
      "26200: running_score:-1458.46, is_best:False\n",
      "26300: running_score:-1395.62, is_best:False\n",
      "26400: running_score:-1428.38, is_best:False\n",
      "26500: running_score:-1460.73, is_best:False\n",
      "26600: running_score:-1471.73, is_best:False\n",
      "26700: running_score:-1304.71, is_best:False\n",
      "26800: running_score:-1355.28, is_best:False\n",
      "26900: running_score:-1440.10, is_best:False\n",
      "27000: running_score:-1367.70, is_best:False\n",
      "27100: running_score:-1493.25, is_best:False\n",
      "27200: running_score:-1420.56, is_best:False\n",
      "27300: running_score:-1414.44, is_best:False\n",
      "27400: running_score:-1372.59, is_best:False\n",
      "27500: running_score:-1387.23, is_best:False\n",
      "27600: running_score:-1467.96, is_best:False\n",
      "27700: running_score:-1455.21, is_best:False\n",
      "27800: running_score:-1395.73, is_best:False\n",
      "27900: running_score:-1392.00, is_best:False\n",
      "28000: running_score:-1382.57, is_best:False\n",
      "28100: running_score:-1447.82, is_best:False\n",
      "28200: running_score:-1398.95, is_best:False\n",
      "28300: running_score:-1470.09, is_best:False\n",
      "28400: running_score:-1520.69, is_best:False\n",
      "28500: running_score:-1406.75, is_best:False\n",
      "28600: running_score:-1465.65, is_best:False\n",
      "28700: running_score:-1450.17, is_best:False\n",
      "28800: running_score:-1480.65, is_best:False\n",
      "28900: running_score:-1476.39, is_best:False\n",
      "29000: running_score:-1435.15, is_best:False\n",
      "29100: running_score:-1460.85, is_best:False\n",
      "29200: running_score:-1472.23, is_best:False\n",
      "29300: running_score:-1386.72, is_best:False\n",
      "29400: running_score:-1383.54, is_best:False\n",
      "29500: running_score:-1451.29, is_best:False\n",
      "29600: running_score:-1413.49, is_best:False\n",
      "29700: running_score:-1310.12, is_best:False\n",
      "29800: running_score:-1412.26, is_best:False\n",
      "29900: running_score:-1363.15, is_best:False\n",
      "30000: running_score:-1494.48, is_best:False\n",
      "30100: running_score:-1383.70, is_best:False\n",
      "30200: running_score:-1387.51, is_best:False\n",
      "30300: running_score:-1434.84, is_best:False\n",
      "30400: running_score:-1296.37, is_best:False\n",
      "30500: running_score:-1351.92, is_best:False\n",
      "30600: running_score:-1396.11, is_best:False\n",
      "30700: running_score:-1486.21, is_best:False\n",
      "30800: running_score:-1474.12, is_best:False\n",
      "30900: running_score:-1482.13, is_best:False\n",
      "31000: running_score:-1493.25, is_best:False\n",
      "31100: running_score:-1440.32, is_best:False\n",
      "31200: running_score:-1501.04, is_best:False\n",
      "31300: running_score:-1342.12, is_best:False\n",
      "31400: running_score:-1498.90, is_best:False\n",
      "31500: running_score:-1412.29, is_best:False\n",
      "31600: running_score:-1418.20, is_best:False\n",
      "31700: running_score:-1376.85, is_best:False\n",
      "31800: running_score:-1396.40, is_best:False\n",
      "31900: running_score:-1495.49, is_best:False\n",
      "32000: running_score:-1291.35, is_best:False\n",
      "32100: running_score:-1408.75, is_best:False\n",
      "32200: running_score:-1521.09, is_best:False\n",
      "32300: running_score:-1488.51, is_best:False\n",
      "32400: running_score:-1343.43, is_best:False\n",
      "32500: running_score:-1400.44, is_best:False\n",
      "32600: running_score:-1459.87, is_best:False\n",
      "32700: running_score:-1474.23, is_best:False\n",
      "32800: running_score:-1447.99, is_best:False\n",
      "32900: running_score:-1389.63, is_best:False\n",
      "33000: running_score:-1408.66, is_best:False\n",
      "33100: running_score:-1491.63, is_best:False\n",
      "33200: running_score:-1445.90, is_best:False\n",
      "33300: running_score:-1488.81, is_best:False\n",
      "33400: running_score:-1373.58, is_best:False\n",
      "33500: running_score:-1484.26, is_best:False\n",
      "33600: running_score:-1390.70, is_best:False\n",
      "33700: running_score:-1479.82, is_best:False\n",
      "33800: running_score:-1478.75, is_best:False\n",
      "33900: running_score:-1424.79, is_best:False\n",
      "34000: running_score:-1359.07, is_best:False\n",
      "34100: running_score:-1466.94, is_best:False\n",
      "34200: running_score:-1443.87, is_best:False\n",
      "34300: running_score:-1465.59, is_best:False\n",
      "34400: running_score:-1423.64, is_best:False\n",
      "34500: running_score:-1420.37, is_best:False\n",
      "34600: running_score:-1420.43, is_best:False\n",
      "34700: running_score:-1462.16, is_best:False\n",
      "34800: running_score:-1381.29, is_best:False\n",
      "34900: running_score:-1443.98, is_best:False\n",
      "35000: running_score:-1406.78, is_best:False\n",
      "35100: running_score:-1401.17, is_best:False\n",
      "35200: running_score:-1447.40, is_best:False\n",
      "35300: running_score:-1371.85, is_best:False\n",
      "35400: running_score:-1504.75, is_best:False\n",
      "35500: running_score:-1461.97, is_best:False\n",
      "35600: running_score:-1318.36, is_best:False\n",
      "35700: running_score:-1537.03, is_best:False\n",
      "35800: running_score:-1480.91, is_best:False\n",
      "35900: running_score:-1375.60, is_best:False\n",
      "36000: running_score:-1421.42, is_best:False\n",
      "36100: running_score:-1402.26, is_best:False\n",
      "36200: running_score:-1430.62, is_best:False\n",
      "36300: running_score:-1411.43, is_best:False\n",
      "36400: running_score:-1463.21, is_best:False\n",
      "36500: running_score:-1403.89, is_best:False\n",
      "36600: running_score:-1404.59, is_best:False\n",
      "36700: running_score:-1376.96, is_best:False\n",
      "36800: running_score:-1412.33, is_best:False\n",
      "36900: running_score:-1479.39, is_best:False\n",
      "37000: running_score:-1446.15, is_best:False\n",
      "37100: running_score:-1411.46, is_best:False\n",
      "37200: running_score:-1367.98, is_best:False\n",
      "37300: running_score:-1499.45, is_best:False\n",
      "37400: running_score:-1477.14, is_best:False\n",
      "37500: running_score:-1410.32, is_best:False\n",
      "37600: running_score:-1409.61, is_best:False\n",
      "37700: running_score:-1383.30, is_best:False\n",
      "37800: running_score:-1456.90, is_best:False\n",
      "37900: running_score:-1373.44, is_best:False\n",
      "38000: running_score:-1456.61, is_best:False\n",
      "38100: running_score:-1388.96, is_best:False\n",
      "38200: running_score:-1403.42, is_best:False\n",
      "38300: running_score:-1362.76, is_best:False\n",
      "38400: running_score:-1350.37, is_best:False\n",
      "38500: running_score:-1253.60, is_best:False\n",
      "38600: running_score:-1435.41, is_best:False\n",
      "38700: running_score:-1356.68, is_best:False\n",
      "38800: running_score:-1462.27, is_best:False\n",
      "38900: running_score:-1474.76, is_best:False\n",
      "39000: running_score:-1522.56, is_best:False\n",
      "39100: running_score:-1365.26, is_best:False\n",
      "39200: running_score:-1466.13, is_best:False\n",
      "39300: running_score:-1381.45, is_best:False\n",
      "39400: running_score:-1406.63, is_best:False\n",
      "39500: running_score:-1343.82, is_best:False\n",
      "39600: running_score:-1463.20, is_best:False\n",
      "39700: running_score:-1459.58, is_best:False\n",
      "39800: running_score:-1385.37, is_best:False\n",
      "39900: running_score:-1503.19, is_best:False\n",
      "40000: running_score:-1448.96, is_best:False\n",
      "40100: running_score:-1404.44, is_best:False\n",
      "40200: running_score:-1437.05, is_best:False\n",
      "40300: running_score:-1399.95, is_best:False\n",
      "40400: running_score:-1397.64, is_best:False\n",
      "40500: running_score:-1387.12, is_best:False\n",
      "40600: running_score:-1452.89, is_best:False\n",
      "40700: running_score:-1466.90, is_best:False\n",
      "40800: running_score:-1358.12, is_best:False\n",
      "40900: running_score:-1372.63, is_best:False\n",
      "41000: running_score:-1494.85, is_best:False\n",
      "41100: running_score:-1429.14, is_best:False\n",
      "41200: running_score:-1495.28, is_best:False\n",
      "41300: running_score:-1387.03, is_best:False\n",
      "41400: running_score:-1439.10, is_best:False\n",
      "41500: running_score:-1415.87, is_best:False\n",
      "41600: running_score:-1453.77, is_best:False\n",
      "41700: running_score:-1423.06, is_best:False\n",
      "41800: running_score:-1455.24, is_best:False\n",
      "41900: running_score:-1446.29, is_best:False\n",
      "42000: running_score:-1512.36, is_best:False\n",
      "42100: running_score:-1432.48, is_best:False\n",
      "42200: running_score:-1447.77, is_best:False\n",
      "42300: running_score:-1426.56, is_best:False\n",
      "42400: running_score:-1429.70, is_best:False\n",
      "42500: running_score:-1447.94, is_best:False\n",
      "42600: running_score:-1467.34, is_best:False\n",
      "42700: running_score:-1384.70, is_best:False\n",
      "42800: running_score:-1346.96, is_best:False\n",
      "42900: running_score:-1306.49, is_best:False\n",
      "43000: running_score:-1418.00, is_best:False\n",
      "43100: running_score:-1467.42, is_best:False\n",
      "43200: running_score:-1448.55, is_best:False\n",
      "43300: running_score:-1434.05, is_best:False\n",
      "43400: running_score:-1386.76, is_best:False\n",
      "43500: running_score:-1445.90, is_best:False\n",
      "43600: running_score:-1450.94, is_best:False\n",
      "43700: running_score:-1431.22, is_best:False\n",
      "43800: running_score:-1468.23, is_best:False\n",
      "43900: running_score:-1430.37, is_best:False\n",
      "44000: running_score:-1447.79, is_best:False\n",
      "44100: running_score:-1406.00, is_best:False\n",
      "44200: running_score:-1431.59, is_best:False\n",
      "44300: running_score:-1514.88, is_best:False\n",
      "44400: running_score:-1423.09, is_best:False\n",
      "44500: running_score:-1406.65, is_best:False\n",
      "44600: running_score:-1393.46, is_best:False\n",
      "44700: running_score:-1517.34, is_best:False\n",
      "44800: running_score:-1444.33, is_best:False\n",
      "44900: running_score:-1488.21, is_best:False\n",
      "45000: running_score:-1443.76, is_best:False\n",
      "45100: running_score:-1451.88, is_best:False\n",
      "45200: running_score:-1536.02, is_best:False\n",
      "45300: running_score:-1402.11, is_best:False\n",
      "45400: running_score:-1438.71, is_best:False\n",
      "45500: running_score:-1327.78, is_best:False\n",
      "45600: running_score:-1526.60, is_best:False\n",
      "45700: running_score:-1443.01, is_best:False\n",
      "45800: running_score:-1345.30, is_best:False\n",
      "45900: running_score:-1440.53, is_best:False\n",
      "46000: running_score:-1444.42, is_best:False\n",
      "46100: running_score:-1482.84, is_best:False\n",
      "46200: running_score:-1366.89, is_best:False\n",
      "46300: running_score:-1368.49, is_best:False\n",
      "46400: running_score:-1451.66, is_best:False\n",
      "46500: running_score:-1392.44, is_best:False\n",
      "46600: running_score:-1389.83, is_best:False\n",
      "46700: running_score:-1335.10, is_best:False\n",
      "46800: running_score:-1507.26, is_best:False\n",
      "46900: running_score:-1442.47, is_best:False\n",
      "47000: running_score:-1432.72, is_best:False\n",
      "47100: running_score:-1428.00, is_best:False\n",
      "47200: running_score:-1417.69, is_best:False\n",
      "47300: running_score:-1430.46, is_best:False\n",
      "47400: running_score:-1477.79, is_best:False\n",
      "47500: running_score:-1416.62, is_best:False\n",
      "47600: running_score:-1405.36, is_best:False\n",
      "47700: running_score:-1420.27, is_best:False\n",
      "47800: running_score:-1478.04, is_best:False\n",
      "47900: running_score:-1466.28, is_best:False\n",
      "48000: running_score:-1516.34, is_best:False\n",
      "48100: running_score:-1345.41, is_best:False\n",
      "48200: running_score:-1374.75, is_best:False\n",
      "48300: running_score:-1439.65, is_best:False\n",
      "48400: running_score:-1450.22, is_best:False\n",
      "48500: running_score:-1472.29, is_best:False\n",
      "48600: running_score:-1459.11, is_best:False\n",
      "48700: running_score:-1457.27, is_best:False\n",
      "48800: running_score:-1398.97, is_best:False\n",
      "48900: running_score:-1386.66, is_best:False\n",
      "49000: running_score:-1372.46, is_best:False\n",
      "49100: running_score:-1444.94, is_best:False\n",
      "49200: running_score:-1268.34, is_best:False\n",
      "49300: running_score:-1398.79, is_best:False\n",
      "49400: running_score:-1479.90, is_best:False\n",
      "49500: running_score:-1421.24, is_best:False\n",
      "49600: running_score:-1365.41, is_best:False\n",
      "49700: running_score:-1484.25, is_best:False\n",
      "49800: running_score:-1499.53, is_best:False\n",
      "49900: running_score:-1502.64, is_best:False\n",
      "50000: running_score:-1478.15, is_best:False\n"
     ]
    }
   ],
   "source": [
    "agent.train(env, update_limit=50000, samples_per_update=100, lr_policy=1e-4, lr_value=1e-3, checkpoint=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Pendulum-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 8.], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1., -1., -8.], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch0.4]",
   "language": "python",
   "name": "conda-env-pytorch0.4-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
